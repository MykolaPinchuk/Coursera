{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\" This is the main script for eap ml project, which plays with all ml methods, applicable for cpcrsp analysis\nCreated on Sat Feb 12 15:19:54 2022\n\"\"\"\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport warnings\nimport random\nimport gc, time\nimport dill\nimport statsmodels.api as sm\nfrom sklearn.svm import SVR\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNetCV\nfrom sklearn import svm\nfrom sklearn.decomposition import PCA, KernelPCA\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import r2_score\n\nfrom xgboost import XGBRegressor\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nplt.style.use('seaborn-white')\nwarnings.simplefilter(action='ignore')\npd.set_option('display.max_columns', 40)\ngc.enable()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T22:39:09.250624Z","iopub.execute_input":"2022-04-10T22:39:09.250868Z","iopub.status.idle":"2022-04-10T22:39:09.260769Z","shell.execute_reply.started":"2022-04-10T22:39:09.250838Z","shell.execute_reply":"2022-04-10T22:39:09.259710Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","metadata":{"execution":{"iopub.status.busy":"2022-04-10T22:41:57.362680Z","iopub.execute_input":"2022-04-10T22:41:57.362955Z","iopub.status.idle":"2022-04-10T22:41:57.373876Z","shell.execute_reply.started":"2022-04-10T22:41:57.362908Z","shell.execute_reply":"2022-04-10T22:41:57.372964Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Found GPU at: /device:GPU:0\n","output_type":"stream"},{"name":"stderr","text":"2022-04-10 22:41:57.364812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-10 22:41:57.365471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-10 22:41:57.365862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-10 22:41:57.366322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-10 22:41:57.366708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-10 22:41:57.367044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"config = tf.ConfigProto()\n\nwith tf.device('/cpu:0'):\n    random_image_cpu = tf.random_normal((100, 100, 100, 3))\n    net_cpu = tf.layers.conv2d(random_image_cpu, 32, 7)\n    net_cpu = tf.reduce_sum(net_cpu)\n\nwith tf.device('/gpu:0'):\n    random_image_gpu = tf.random_normal((100, 100, 100, 3))\n    net_gpu = tf.layers.conv2d(random_image_gpu, 32, 7)\n    net_gpu = tf.reduce_sum(net_gpu)\n\nsess = tf.Session(config=config)\nsess.run(tf.global_variables_initializer())\n\ncpu = lambda : sess.run(net_cpu)\ngpu = lambda : sess.run(net_gpu)\n  \nprint('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n      '(batch x height x width x channel). Sum of ten runs.')\nprint('CPU (s):')\ncpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\nprint(cpu_time)\nprint('GPU (s):')\ngpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\nprint(gpu_time)\nprint('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))\n\nsess.close()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T22:42:27.963814Z","iopub.execute_input":"2022-04-10T22:42:27.964182Z","iopub.status.idle":"2022-04-10T22:42:28.008870Z","shell.execute_reply.started":"2022-04-10T22:42:27.964143Z","shell.execute_reply":"2022-04-10T22:42:28.006800Z"},"trusted":true},"execution_count":10,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/3317691100.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/cpu:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mrandom_image_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnet_cpu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_image_cpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'ConfigProto'"],"ename":"AttributeError","evalue":"module 'tensorflow' has no attribute 'ConfigProto'","output_type":"error"}]},{"cell_type":"code","source":"path = '../input/mleap-data/'\n\ns_train_X = pd.read_csv(path + 's_train_X.csv')\ns_train_y = pd.read_csv(path + 's_train_y.csv')\ns_test_X = pd.read_csv(path + 's_test_X.csv')\ns_test_y = pd.read_csv(path + 's_test_y.csv')\nsp_train_X = pd.read_csv(path + 'sp_train_X.csv')\nlp_train_X = pd.read_csv(path + 'lp_train_X.csv')\nsp_test_X = pd.read_csv(path + 'sp_test_X.csv')\nlp_test_X = pd.read_csv(path + 'lp_test_X.csv')\n\ns_train_X.drop(columns='Unnamed: 0', inplace=True)\ns_train_y.drop(columns='Unnamed: 0', inplace=True)\ns_test_X.drop(columns='Unnamed: 0', inplace=True)\nsp_train_X.drop(columns='Unnamed: 0', inplace=True)\nlp_train_X.drop(columns='Unnamed: 0', inplace=True)\nlp_test_X.drop(columns='Unnamed: 0', inplace=True)\n\ns_train_X = np.array(s_train_X)\ns_train_y = np.array(s_train_y)\ns_test_X = np.array(s_test_X)\ns_test_y = np.array(s_test_y)\nsp_train_X = np.array(sp_train_X)\nlp_train_X = np.array(lp_train_X)\nsp_test_X = np.array(sp_test_X)\nlp_test_X = np.array(lp_test_X)\n\nprint(s_train_X.shape)\nprint(s_train_y.shape)\nprint(s_test_X.shape)\nprint(s_test_y.shape)\nprint(sp_train_X.shape)\nprint(lp_train_X.shape)\nprint(sp_test_X.shape)\nprint(lp_test_X.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T22:32:46.224912Z","iopub.execute_input":"2022-04-10T22:32:46.225177Z","iopub.status.idle":"2022-04-10T22:33:31.634378Z","shell.execute_reply.started":"2022-04-10T22:32:46.225142Z","shell.execute_reply":"2022-04-10T22:33:31.633566Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"(1257579, 27)\n(1257579, 1)\n(100000, 27)\n(100000, 1)\n(1257579, 10)\n(1257579, 50)\n(100000, 10)\n(100000, 50)\n","output_type":"stream"}]},{"cell_type":"code","source":"model_ann5_s = Sequential([\n    BatchNormalization(input_shape=(27,)),\n    Dense(256, activation='relu'),\n    Dropout(0.4),\n    BatchNormalization(),\n    Dense(256, activation='relu'),\n    Dropout(0.4),\n    BatchNormalization(),\n    Dense(256, activation='relu'),\n    Dropout(0.4),\n    BatchNormalization(),\n    Dense(64, activation='relu'),\n    Dropout(0.4),\n    BatchNormalization(),\n    Dense(16, activation='relu'),\n    Dropout(0.4),\n    BatchNormalization(),\n    Dense(1)])\n\nprint(model_ann5_s.count_params())","metadata":{"execution":{"iopub.status.busy":"2022-04-10T22:34:23.888230Z","iopub.execute_input":"2022-04-10T22:34:23.888582Z","iopub.status.idle":"2022-04-10T22:34:26.374898Z","shell.execute_reply.started":"2022-04-10T22:34:23.888547Z","shell.execute_reply":"2022-04-10T22:34:26.374219Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"159757\n","output_type":"stream"},{"name":"stderr","text":"2022-04-10 22:34:24.009133: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-10 22:34:24.116103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-10 22:34:24.117285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-10 22:34:24.118784: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-04-10 22:34:24.120153: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-10 22:34:24.120861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-10 22:34:24.121680: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-10 22:34:25.938173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-10 22:34:25.939071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-10 22:34:25.939789: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-04-10 22:34:25.940488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"time1 = time.time()\n\nearly_stopping20 = EarlyStopping(patience=20)\nearly_stopping15 = EarlyStopping(patience=15)\nearly_stopping10 = EarlyStopping(patience=10)\nearly_stopping5 = EarlyStopping(patience=5)\n\n\nmodel_ann5_s.compile(loss= \"mean_squared_error\" , optimizer=\"adam\", metrics=[\"mean_squared_error\"])\nhistory = model_ann5_s.fit(s_train_X, s_train_y, validation_data=(s_test_X, s_test_y), \n                         batch_size=128, epochs=5, verbose=2, callbacks=[early_stopping5])\nhistory_df = pd.DataFrame(history.history)\nhistory_df.loc[:, ['loss', 'val_loss']].plot()\nprint(\"Minimum Validation Loss: {:0.4f}\".format(history_df['val_loss'].min()))\n\nann_s = [r2_score(s_train_y, model_ann5_s.predict(s_train_X)), \n       r2_score(s_test_y, model_ann5_s.predict(s_test_X))]\n\nprint('time is ', time.time()-time1)","metadata":{"execution":{"iopub.status.busy":"2022-04-10T22:39:15.404335Z","iopub.execute_input":"2022-04-10T22:39:15.404582Z","iopub.status.idle":"2022-04-10T22:41:47.666015Z","shell.execute_reply.started":"2022-04-10T22:39:15.404554Z","shell.execute_reply":"2022-04-10T22:41:47.664973Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Epoch 1/5\n9825/9825 - 56s - loss: 0.9948 - mean_squared_error: 0.9948 - val_loss: 1.1291 - val_mean_squared_error: 1.1291\nEpoch 2/5\n9825/9825 - 55s - loss: 0.9938 - mean_squared_error: 0.9938 - val_loss: 1.1295 - val_mean_squared_error: 1.1295\nEpoch 3/5\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_33/3948165770.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel_ann5_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"mean_squared_error\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean_squared_error\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m history = model_ann5_s.fit(s_train_X, s_train_y, validation_data=(s_test_X, s_test_y), \n\u001b[0;32m---> 11\u001b[0;31m                          batch_size=128, epochs=5, verbose=2, callbacks=[early_stopping5])\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mhistory_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mhistory_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"ann_s ","metadata":{"execution":{"iopub.status.busy":"2022-02-19T00:31:40.68045Z","iopub.execute_input":"2022-02-19T00:31:40.680918Z","iopub.status.idle":"2022-02-19T00:31:40.686436Z","shell.execute_reply.started":"2022-02-19T00:31:40.680881Z","shell.execute_reply":"2022-02-19T00:31:40.685708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shap\nshap.initjs()\n\n# explain the model's predictions using SHAP\n# (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\nexplainer = shap.TreeExplainer(model_ann5_s)\nshap_values = explainer.shap_values(s_train_X)\n\n# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\nshap.force_plot(explainer.expected_value, shap_values[0,:], s_train_X.iloc[0,:])\n\nshap.summary_plot(shap_values, s_train_X, plot_type=\"bar\")","metadata":{"execution":{"iopub.status.busy":"2022-02-19T00:31:40.687864Z","iopub.execute_input":"2022-02-19T00:31:40.688345Z","iopub.status.idle":"2022-02-19T00:31:41.85982Z","shell.execute_reply.started":"2022-02-19T00:31:40.688308Z","shell.execute_reply":"2022-02-19T00:31:41.858623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"explainer = shap.GradientExplainer(model_ann5_s, s_train_X)\n#shap_values = explainer.shap_values(s_test_X)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T00:35:57.908301Z","iopub.execute_input":"2022-02-19T00:35:57.908603Z","iopub.status.idle":"2022-02-19T00:35:57.922209Z","shell.execute_reply.started":"2022-02-19T00:35:57.908567Z","shell.execute_reply":"2022-02-19T00:35:57.921518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap_values = explainer.shap_values(s_test_X)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T00:36:03.069797Z","iopub.execute_input":"2022-02-19T00:36:03.070066Z","iopub.status.idle":"2022-02-19T00:36:04.37571Z","shell.execute_reply.started":"2022-02-19T00:36:03.070035Z","shell.execute_reply":"2022-02-19T00:36:04.374023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.summary_plot(shap_values[0], plot_type = 'bar', feature_names = test_data.columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"shap.summary_plot(shap_values[0], plot_type = 'bar', feature_names = test_data.columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\n\nwith open(\"ann_results_2\", \"wb\") as fp:   #Pickling\n    pickle.dump(ann_results, fp)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T22:32:10.220741Z","iopub.execute_input":"2022-02-16T22:32:10.220996Z","iopub.status.idle":"2022-02-16T22:32:10.22767Z","shell.execute_reply.started":"2022-02-16T22:32:10.220966Z","shell.execute_reply":"2022-02-16T22:32:10.226892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp = pd.DataFrame(ann_results)\ntemp.to_csv('ann_results_2.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-16T22:33:42.390838Z","iopub.execute_input":"2022-02-16T22:33:42.391381Z","iopub.status.idle":"2022-02-16T22:33:42.398448Z","shell.execute_reply.started":"2022-02-16T22:33:42.391342Z","shell.execute_reply":"2022-02-16T22:33:42.397766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tensorflow==2.5.0\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nprint (tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T00:23:42.354186Z","iopub.execute_input":"2022-02-19T00:23:42.354433Z","iopub.status.idle":"2022-02-19T00:23:51.372309Z","shell.execute_reply.started":"2022-02-19T00:23:42.3544Z","shell.execute_reply":"2022-02-19T00:23:51.371436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (tf.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-02-19T00:33:30.350619Z","iopub.execute_input":"2022-02-19T00:33:30.350885Z","iopub.status.idle":"2022-02-19T00:33:30.356279Z","shell.execute_reply.started":"2022-02-19T00:33:30.350856Z","shell.execute_reply":"2022-02-19T00:33:30.355206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import the modules we'll need\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T22:37:33.749926Z","iopub.execute_input":"2022-02-16T22:37:33.75072Z","iopub.status.idle":"2022-02-16T22:37:33.757394Z","shell.execute_reply.started":"2022-02-16T22:37:33.750675Z","shell.execute_reply":"2022-02-16T22:37:33.756561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_download_link(temp)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T22:37:52.785829Z","iopub.execute_input":"2022-02-16T22:37:52.786086Z","iopub.status.idle":"2022-02-16T22:37:52.792941Z","shell.execute_reply.started":"2022-02-16T22:37:52.786055Z","shell.execute_reply":"2022-02-16T22:37:52.791971Z"},"trusted":true},"execution_count":null,"outputs":[]}]}